#C:\Users\ilua-pc\Desktop\Export\AI-expert_call\app\comparator.py
import json
from typing import Dict, List, Optional
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
import torch
import ollama

# ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹, Ğ¿Ğ¾ ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¼ ÑÑ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°ĞµĞ¼
KEY_PARAMS = [
    ("max_speed_kmh",    {"ru": "ĞœĞ°ĞºÑ. ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚ÑŒ (ĞºĞ¼/Ñ‡)", "en": "Max Speed (km/h)",    "cn": "æœ€å¤§é€Ÿåº¦ (å…¬é‡Œ/å°æ—¶)"}),
    ("flight_time_min",  {"ru": "Ğ’Ñ€ĞµĞ¼Ñ Ğ¿Ğ¾Ğ»Ñ‘Ñ‚Ğ° (Ğ¼Ğ¸Ğ½)",    "en": "Flight Time (min)",    "cn": "é£è¡Œæ—¶é—´ (åˆ†é’Ÿ)"}),
    ("max_payload_kg",   {"ru": "ĞŸĞ¾Ğ»ĞµĞ·Ğ½Ğ°Ñ Ğ½Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° (ĞºĞ³)", "en": "Max Payload (kg)",     "cn": "æœ‰æ•ˆè½½è· (å…¬æ–¤)"}),
    ("max_range_km",     {"ru": "Ğ”Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ (ĞºĞ¼)",        "en": "Max Range (km)",       "cn": "æœ€å¤§èˆªç¨‹ (å…¬é‡Œ)"}),
]

# Ğ¢ĞµĞºÑÑ‚Ñ‹ Ğ´Ğ»Ñ Â«Ğ½Ğ¸Ñ‡ÑŒÑÂ»
TIE_LABEL = {"ru": "ĞĞ¸Ñ‡ÑŒÑ", "en": "Tie", "cn": "å¹³å±€"}


def load_db(path: str = "app/static_files/db.json") -> Dict[str, Dict]:
    with open(path, encoding="utf-8") as f:
        return json.load(f)


def _get_value(specs: Dict, key: str) -> Optional[float]:
    perf = specs.get("performance", {})
    w = specs.get("weights", {})
    val = perf.get(key)
    if val is None:
        val = w.get(key)
    return val


def compare_two_models(
    name_a: str, specs_a: Dict,
    name_b: str, specs_b: Dict,
    lang: str = "ru"
) -> List[str]:
    lines: List[str] = []
    for key, labels in KEY_PARAMS:
        a_val = _get_value(specs_a, key)
        b_val = _get_value(specs_b, key)
        if a_val is None or b_val is None:
            continue

        if a_val > b_val:
            winner = name_a
        elif b_val > a_val:
            winner = name_b
        else:
            winner = TIE_LABEL[lang]

        label = labels[lang]
        lines.append(f"{label}: {a_val} vs {b_val} â†’ {winner}")
    return lines


def compare_main_vs(
    main: str,
    competitors: List[str],
    lang: str = "ru"
) -> str:
    """
    Ğ¡Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ¾Ğ´Ğ½Ñƒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ main Ñ Ğ»Ğ¸ÑÑ‚Ğ¾Ğ¼ competitors, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ DeepSeek Ñ‡ĞµÑ€ĞµĞ· Ollama.
    """
    db = load_db()
    specs_main = db.get(main)
    if not specs_main:
        return {"ru":"ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ° Ğ² Ğ±Ğ°Ğ·Ğµ.","en":"Model not found.","cn":"æœªæ‰¾åˆ°è¯¥å‹å·ã€‚"}[lang]

    report_lines: List[str] = []
    report_lines.append({
        'ru': f"ğŸ“Š Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Â«{main}Â» Ñ ĞºĞ¾Ğ½ĞºÑƒÑ€ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸:",
        'en': f"ğŸ“Š Comparison of {main} vs competitors:",
        'cn': f"ğŸ“Š {main} ä¸ç«å“æ¯”è¾ƒï¼š"
    }[lang])
    report_lines.append("")

    for comp in competitors:
        specs_comp = db.get(comp)
        if not specs_comp:
            report_lines.append({
                'ru': f"ĞšĞ¾Ğ½ĞºÑƒÑ€ĞµĞ½Ñ‚ {comp} Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½.",
                'en': f"Competitor {comp} not found.",
                'cn': f"æœªæ‰¾åˆ°ç«å“ {comp}ã€‚"
            }[lang])
            continue
        # Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ
        report_lines.append({
            'ru': f"â€” {main} vs {comp}:", 'en': f"â€” {main} vs {comp}:", 'cn': f"â€” {main} vs {comp}ï¼š"
        }[lang])
        report_lines.extend(compare_two_models(main, specs_main, comp, specs_comp, lang))
        report_lines.append("")

        # ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° prompt Ğ´Ğ»Ñ DeepSeek
        summary_prompt = f"Compare these two VTOL drones: {main} and {comp}. Specs of {main}: {json.dumps(specs_main)}. Specs of {comp}: {json.dumps(specs_comp)}. Summarize the key differences and which is better overall."

        try:
            deepseek_response = ollama.chat(
                model='deepseek-r1:8b',
                messages=[{'role': 'user', 'content': summary_prompt}]
            )
            deepseek_text = deepseek_response['message']['content']
        except Exception as e:
            deepseek_text = f"[DeepSeek error: {e}]"

        report_lines.append({
            'ru': 'ğŸ¤– ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ˜Ğ˜:', 'en': 'ğŸ¤– AI analysis:', 'cn': 'ğŸ¤– AIåˆ†æï¼š'
        }[lang])
        report_lines.append(deepseek_text)
        report_lines.append("")

    return "\n".join(report_lines)


def list_by_country(
    country: str,
    lang: str = "ru"
) -> str:
    db = load_db()
    filtered = [name for name, spec in db.items() if spec.get("country","...").lower() == country.lower()]
    if not filtered:
        return {"ru": f"ĞœĞ¾Ğ´ĞµĞ»Ğ¸ Ğ¸Ğ· {country} Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹.", "en": f"No models from {country}.", "cn": f"æœªæ‰¾åˆ°æ¥è‡ª{country}çš„å‹å·ã€‚"}[lang]
    header = {"ru": f"Ğ”Ñ€Ğ¾Ğ½Ñ‹ Ğ¸Ğ· {country}:", "en": f"Drones from {country}:", "cn": f"æ¥è‡ª{country}çš„æ— äººæœºï¼š"}[lang]
    return "\n".join([header] + [f"â€¢ {n}" for n in filtered])
